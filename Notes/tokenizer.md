# Tokenization

## Overview
- Tokenization is the process of converting raw text into a sequence of tokens(numbers) that a Large Language Model can process.
- These tokens can represent characters,subwords, or words depending on the tokenization strategy.
- 

### Input
A raw sentence, for example: 
"This is an input text."

## Output:
A sequence of integers that correspond to tokens in the tokenizer's vocabulary.
The process of tokenization is shown in the diagram below:
![Output Example](../assets/tokenization.png)




